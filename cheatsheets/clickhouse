-- SQL for Clickhouse (db optimized for log search)

-- ## Datetime functions

-- https://clickhouse.com/docs/en/sql-reference/functions/date-time-functions
toStartOfHour(timestamp) -- : round datetime to start of our

-- In Grafana, you can use those global variables
where timestamp between $__fromTime and $__toTime

-- Something that can be used by Grafana Time Series
-- Needs:
-- datetime as "time" column
-- value as "value" column
-- order by time
with events as (
SELECT
timestamp,
strings['event_type'] AS event_type,
strings['status'] AS status,
FROM default.table_name
WHERE application = 'app_name' AND timestamp >= subtractHours(now(), 24*7)
)

select
toStartOfHour(timestamp) as time,
category,
count(*) as value

from events

where 1=1
and event_type = 'WHATEVER'
and status != 'STATUS_SUCCESSFUL'

group by 1, 2
order by 1

-- success ratio with countIf(...)
select
toStartOfHour(timestamp) as time,
countIf(status = 'STATUS_SUCCESSFUL') / count(*) as value
from events
where event_type = 'WHATEVER'
group by 1
order by 1

-- bar chart
SELECT
    toHour(time) AS h,
    sum(hits) AS t,
    bar(t, 0, max(t) OVER (), 50) AS bar
FROM wikistat
GROUP BY h
ORDER BY h ASC
-- ┌──h─┬─────────t─┬─bar────────────────────────────────────────────────┐
-- │  0 │ 146208847 │ ██████████████████████████████████████▋            │
-- │  1 │ 143713140 │ █████████████████████████████████████▊             |
-- └────┴───────────┴────────────────────────────────────────────────────┘

-- Show errors individually, but start with the stores with the most errors
SELECT
    store_id,
    order_id,
    error_message,
    COUNT(*) OVER (PARTITION BY store_id) AS error_count
FROM
    your_table_name
ORDER BY
    error_count DESC,
    store_id;

-- Group by showing array of grouped values
select
  store_id,
  count(*),
  -- Format string
  arrayMap((x) -> 'https://tools.example.com' || x || '/details', groupArray(order_id))
from
  table_name
group by 1
order by 2 desc;

-- vim: set ft=sql:
